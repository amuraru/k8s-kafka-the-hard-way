apiVersion: kafka.banzaicloud.io/v1beta1
kind: KafkaCluster
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
    cluster_name: "my-kafka-cluster"
  name: kafka
spec:
  propagateLabels: true
  headlessServiceEnabled: true
  ingressController: "envoy"
  zkAddresses:
    - "zk-client.zookeeper:2181"
  zkPath: "/kafka"
  oneBrokerPerNode: false
  # renovate: datasource=docker depName=ghcr.io/adobe/koperator/kafka
  clusterImage: "ghcr.io/adobe/koperator/kafka:2.13-3.9.1"
  clusterWideConfig: |
    # dynamic config
  readOnlyConfig: |
    auto.create.topics.enable: false
    inter.broker.protocol.version: 3.9
    # we disable auto leader rebalance b/c Cruise Control already does that and that would conflict
    auto.leader.rebalance.enable: false
    cruise.control.metrics.reporter.acks: 1
    cruise.control.metrics.topic: __CruiseControlMetrics
    num.io.threads: 12
    min.insync.replicas: 2
    num.network.threads: 12
    num.replica.fetchers: 4
    default.replication.factor: 3
    num.partitions: 10
    # Let underlying OS to auto-tune the socket buffers
    socket.receive.buffer.bytes: -1
    socket.send.buffer.bytes: -1
    replica.socket.receive.buffer.bytes: -1
    # Override log segment size to expedite compaction
    log.segment.bytes: 536870912
    # Increase the number active consumer fetch session to avoid evictions
    max.incremental.fetch.session.cache.slots: 4000
    # increase the background jobs that handle consumer groups chore
    background.threads: 20
  rackAwareness:
    # operator will use these labels from the nodes to create the rack for Kafka
    labels:
      - "topology.kubernetes.io/region"
      - "topology.kubernetes.io/zone"
  brokerConfigGroups:
    rack1:
      nodeSelector:
        topology.kubernetes.io/zone: az1
      resourceRequirements:
        limits:
          memory: "5Gi"
          cpu: "5"
        requests:
          memory: "2Gi"
          cpu: "2"
      # nodeAffinity can be specified, operator populates this value if new pvc added later to brokers
      # nodeAffinity:
      # nodeSelector can be specified, which set the pod to fit on a node
      # nodeSelector:
      # tolerations can be specified, which set the pod's tolerations
      # tolerations:
      # config parameter can be used to pass Kafka config https://kafka.apache.org/documentation/#brokerconfigs
      # which has type per-broker
      #config: |
      #  sasl.enabled.mechanisms=PLAIN
      # serviceAccountName specifies the serviceAccount used for this specific broker
      #serviceAccountName: "kafka"
      # imagePullSecrets specifies the secret to use when using private registry
      #imagePullSecrets: "k8ssecret"
      # kafkaHeapOpts specifies the jvm heap size for the broker
      kafkaHeapOpts: "-XX:InitialRAMPercentage=30 -XX:MaxRAMPercentage=70 -XX:MinRAMPercentage=70"
      # kafkaJvmPerfOpts specifies the jvm performance configs for the broker
      kafkaJvmPerfOpts: "-server -XX:+UseG1GC -XX:MetaspaceSize=96m -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true -Dsun.net.inetaddr.ttl=60"
      storageConfigs:
        - mountPath: "/kafka-logs1"
          pvcSpec:
            accessModes:
              - ReadWriteOnce
            storageClassName: standard
            resources:
              requests:
                storage: 10Gi
    rack2:
      nodeSelector:
        topology.kubernetes.io/zone: az2
      resourceRequirements:
        limits:
          memory: "5Gi"
          cpu: "5"
        requests:
          memory: "2Gi"
          cpu: "2"
      # kafkaHeapOpts specifies the jvm heap size for the broker
      kafkaHeapOpts: "-XX:InitialRAMPercentage=30 -XX:MaxRAMPercentage=70 -XX:MinRAMPercentage=70"
      # kafkaJvmPerfOpts specifies the jvm performance configs for the broker
      kafkaJvmPerfOpts: "-server -XX:+UseG1GC -XX:MetaspaceSize=96m -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true -Dsun.net.inetaddr.ttl=60"
      storageConfigs:
        - mountPath: "/kafka-logs1"
          pvcSpec:
            accessModes:
              - ReadWriteOnce
            storageClassName: standard
            resources:
              requests:
                storage: 10Gi
    rack3:
      nodeSelector:
        topology.kubernetes.io/zone: az3
      resourceRequirements:
        limits:
          memory: "5Gi"
          cpu: "5"
        requests:
          memory: "2Gi"
          cpu: "2"
      # kafkaHeapOpts specifies the jvm heap size for the broker
      kafkaHeapOpts: "-XX:InitialRAMPercentage=30 -XX:MaxRAMPercentage=70 -XX:MinRAMPercentage=70"
      # kafkaJvmPerfOpts specifies the jvm performance configs for the broker
      kafkaJvmPerfOpts: "-server -XX:+UseG1GC -XX:MetaspaceSize=96m -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true -Dsun.net.inetaddr.ttl=60"
      storageConfigs:
        - mountPath: "/kafka-logs1"
          pvcSpec:
            accessModes:
              - ReadWriteOnce
            storageClassName: standard
            resources:
              requests:
                storage: 10Gi
  brokers:
    - brokerConfigGroup: rack1
      id: 101
    - brokerConfigGroup: rack1
      id: 102
    - brokerConfigGroup: rack2
      id: 201
    - brokerConfigGroup: rack2
      id: 202
    - brokerConfigGroup: rack3
      id: 301
    - brokerConfigGroup: rack3
      id: 302
  rollingUpgradeConfig:
    failureThreshold: 1
  listenersConfig:
    internalListeners:
      - type: "plaintext"
        name: "internal"
        containerPort: 29092
        usedForInnerBrokerCommunication: true
      - type: "plaintext"
        name: "controller"
        containerPort: 29093
        usedForInnerBrokerCommunication: false
        usedForControllerCommunication: true
  cruiseControlConfig:
    image: "adobe/cruise-control:3.0.3-adbe-20250804"
    topicConfig:
      partitions: 6
      replicationFactor: 3
    cruiseControlTaskSpec:
      # this is the timeout used in CC to kill rebalance tasks
      # increased this to max as it may lead to data loss when rebalancing lots of brokers and rebalance may take a lot
      # better to keep the task hanging in CC instead of losing data
      RetryDurationMinutes: 2147483647
    # CruiseControlEndpoint describes the endpoint where the already running CC is accessable. If set the Operator will not
    # try to install one
    #cruiseControlEndpoint: "localhost:8090"
    # resourceRequirements works exactly like Container resources, the user can specify the limit and the requests
    # through this property
    resourceRequirements:
     limits:
       memory: "2Gi"
       cpu: "3"
     requests:
       memory: "1Gi"
       cpu: "1"
    # serviceAccountName specifies the serviceAccount used for cc
    #serviceAccountName: "envoy"
    # imagePullSecrets specifies the secret to use when using private registry
    #imagePullSecrets: "k8ssecret"
    # nodeSelector can be specified, which set the pod to fit on a node
    #nodeSelector:
    # tolerations can be specified, which set the pod's tolerations
    #tolerations:
    # Config describes the main configuration file called cruisecontrol.properties bootsrap.server and zookeeper.connect must left out
    # because those values are generated
    config: |
      # Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the "License"). See License in the project root for license information.
      #
      # This is an example property file for Kafka Cruise Control. See KafkaCruiseControlConfig for more details.
      # Configuration for the metadata client.
      # =======================================
      # The maximum interval in milliseconds between two metadata refreshes.
      #metadata.max.age.ms=300000
      # Client id for the Cruise Control. It is used for the metadata client.
      #client.id=kafka-cruise-control
      # The size of TCP send buffer bytes for the metadata client.
      #send.buffer.bytes=131072
      # The size of TCP receive buffer size for the metadata client.
      #receive.buffer.bytes=131072
      # The time to wait before disconnect an idle TCP connection.
      #connections.max.idle.ms=540000
      # The time to wait before reconnect to a given host.
      #reconnect.backoff.ms=50
      # The time to wait for a response from a host after sending a request.
      #request.timeout.ms=30000
      # The time to wait for broker logdir to respond after sending a request.
      #logdir.response.timeout.ms=10000
      # Configurations for the load monitor
      # =======================================
      # The number of metric fetcher thread to fetch metrics for the Kafka cluster
      num.metric.fetchers=1
      # The metric sampler class
      metric.sampler.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsReporterSampler
      # True if the sampling process allows CPU capacity estimation of brokers used for CPU utilization estimation.
      sampling.allow.cpu.capacity.estimation=true
      # Configurations for CruiseControlMetricsReporterSampler
      metric.reporter.topic=__CruiseControlMetrics
      # The sample store class name
      sample.store.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.KafkaSampleStore
      # The config for the Kafka sample store to save the partition metric samples
      partition.metric.sample.store.topic=__KafkaCruiseControlPartitionMetricSamples
      # The config for the Kafka sample store to save the model training samples
      broker.metric.sample.store.topic=__KafkaCruiseControlModelTrainingSamples
      # The replication factor of Kafka metric sample store topic
      sample.store.topic.replication.factor=3
      partition.sample.store.topic.partition.count=15
      broker.sample.store.topic.partition.count=15
      # The config for the number of Kafka sample store consumer threads
      num.sample.loading.threads=8
      # The partition assignor class for the metric samplers
      metric.sampler.partition.assignor.class=com.linkedin.kafka.cruisecontrol.monitor.sampling.DefaultMetricSamplerPartitionAssignor
      # The metric sampling interval in milliseconds
      metric.sampling.interval.ms=60000
      # The partition metrics window size in milliseconds
      partition.metrics.window.ms=300000
      # The number of partition metric windows to keep in memory
      num.partition.metrics.windows=2
      # The minimum partition metric samples required for a partition in each window
      min.samples.per.partition.metrics.window=1
      # The broker metrics window size in milliseconds
      broker.metrics.window.ms=300000
      # The number of broker metric windows to keep in memory
      num.broker.metrics.windows=20
      # The minimum broker metric samples required for a partition in each window
      min.samples.per.broker.metrics.window=1
      # The configuration for the BrokerCapacityConfigFileResolver (supports JBOD, non-JBOD, and heterogeneous CPU core capacities)
      capacity.config.file=config/capacity.json
      # Configurations for the analyzer
      # =======================================
      # The list of goals to optimize the Kafka cluster for with pre-computed proposals
      default.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal
      # The list of supported goals
      goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.PotentialNwOutGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.TopicReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderReplicaDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderBytesInDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.kafkaassigner.KafkaAssignerDiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.kafkaassigner.KafkaAssignerEvenRackAwareGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.PreferredLeaderElectionGoal
      # The list of supported intra-broker goals
      intra.broker.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.IntraBrokerDiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.IntraBrokerDiskUsageDistributionGoal
      # The list of supported hard goals
      hard.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal
      # The minimum percentage of well monitored partitions out of all the partitions
      min.valid.partition.ratio=0.95
      # The balance threshold for CPU
      cpu.balance.threshold=1.3
      # The balance threshold for disk
      disk.balance.threshold=1.3
      # The balance threshold for network inbound utilization
      network.inbound.balance.threshold=1.3
      # The balance threshold for network outbound utilization
      network.outbound.balance.threshold=1.3
      # The balance threshold for the replica count
      replica.count.balance.threshold=1.2
      # The capacity threshold for CPU in percentage
      cpu.capacity.threshold=0.8
      # The capacity threshold for disk in percentage
      disk.capacity.threshold=0.8
      # The capacity threshold for network inbound utilization in percentage
      network.inbound.capacity.threshold=0.8
      # The capacity threshold for network outbound utilization in percentage
      network.outbound.capacity.threshold=0.8
      # The threshold to define the cluster to be in a low CPU utilization state
      cpu.low.utilization.threshold=0.2
      # The threshold to define the cluster to be in a low disk utilization state
      disk.low.utilization.threshold=0.2
      # The threshold to define the cluster to be in a low network inbound utilization state
      network.inbound.low.utilization.threshold=0.2
      # The threshold to define the cluster to be in a low disk utilization state
      network.outbound.low.utilization.threshold=0.2
      # The metric anomaly percentile upper threshold
      metric.anomaly.percentile.upper.threshold=90.0
      # The metric anomaly percentile lower threshold
      metric.anomaly.percentile.lower.threshold=10.0
      # How often should the cached proposal be expired and recalculated if necessary
      proposal.expiration.ms=60000
      # The maximum number of replicas that can reside on a broker at any given time.
      max.replicas.per.broker=10000
      # The number of threads to use for proposal candidate precomputing.
      num.proposal.precompute.threads=1
      # the topics that should be excluded from the partition movement.
      #topics.excluded.from.partition.movement
      # The impact of having one level higher goal priority on the relative balancedness score.
      #goal.balancedness.priority.weight
      # The impact of strictness on the relative balancedness score.
      #goal.balancedness.strictness.weight
      # Configurations for the executor
      # =======================================
      # If true, appropriate zookeeper Client { .. } entry required in jaas file located at $base_dir/config/cruise_control_jaas.conf
      zookeeper.security.enabled=false
      # The max number of partitions to move in/out on a given broker at a given time.
      num.concurrent.partition.movements.per.broker=10
      # The max number of partitions to move between disks within a given broker at a given time.
      num.concurrent.intra.broker.partition.movements=2
      # The max number of leadership movement within the whole cluster at a given time.
      num.concurrent.leader.movements=1000
      default.replica.movement.strategies=com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeSmallReplicaMovementStrategy,com.linkedin.kafka.cruisecontrol.executor.strategy.BaseReplicaMovementStrategy
      # Default replica movement throttle. If not specified, movements unthrottled by default.
      # default.replication.throttle=
      # The interval between two execution progress checks.
      execution.progress.check.interval.ms=10000
      # Configurations for anomaly detector
      # =======================================
      # The goal violation notifier class
      anomaly.notifier.class=com.linkedin.kafka.cruisecontrol.detector.notifier.SelfHealingNotifier
      # The metric anomaly finder class
      metric.anomaly.finder.class=
      # The anomaly detection interval
      anomaly.detection.interval.ms=300000
      # The goal violation to detect.
      anomaly.detection.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal
      self.healing.goals=com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuCapacityGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.CpuUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal,com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal
      # The interested metrics for metric anomaly analyzer.
      metric.anomaly.analyzer.metrics=BROKER_PRODUCE_LOCAL_TIME_MS_MAX,BROKER_PRODUCE_LOCAL_TIME_MS_MEAN,BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_MAX,BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_MEAN,BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_MAX,BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_MEAN,BROKER_LOG_FLUSH_TIME_MS_MAX,BROKER_LOG_FLUSH_TIME_MS_MEAN
      # True if recently demoted brokers are excluded from optimizations during broker failure self healing, false otherwise
      broker.failure.exclude.recently.demoted.brokers=true
      # True if recently removed brokers are excluded from optimizations during broker failure self healing, false otherwise
      broker.failure.exclude.recently.removed.brokers=true
      # True if recently demoted brokers are excluded from optimizations during goal violation self healing, false otherwise
      goal.violation.exclude.recently.demoted.brokers=true
      # True if recently removed brokers are excluded from optimizations during goal violation self healing, false otherwise
      goal.violation.exclude.recently.removed.brokers=true
      # The zk path to store failed broker information.
      failed.brokers.zk.path=/CruiseControlBrokerList
      # Topic config provider class
      topic.config.provider.class=com.linkedin.kafka.cruisecontrol.config.KafkaTopicConfigProvider
      # The cluster configurations for the KafkaTopicConfigProvider
      cluster.configs.file=config/clusterConfigs.json
      # The maximum time in milliseconds to store the response and access details of a completed kafka monitoring user task.
      completed.kafka.monitor.user.task.retention.time.ms=86400000
      # The maximum time in milliseconds to store the response and access details of a completed cruise control monitoring user task.
      completed.cruise.control.monitor.user.task.retention.time.ms=86400000
      # The maximum time in milliseconds to store the response and access details of a completed kafka admin user task.
      completed.kafka.admin.user.task.retention.time.ms=604800000
      # The maximum time in milliseconds to store the response and access details of a completed cruise control admin user task.
      completed.cruise.control.admin.user.task.retention.time.ms=604800000
      # The fallback maximum time in milliseconds to store the response and access details of a completed user task.
      completed.user.task.retention.time.ms=86400000
      # The maximum time in milliseconds to retain the demotion history of brokers.
      demotion.history.retention.time.ms=900000
      # The maximum time in milliseconds to retain the removal history of brokers.
      removal.history.retention.time.ms=900000
      # The maximum number of completed kafka monitoring user tasks for which the response and access details will be cached.
      max.cached.completed.kafka.monitor.user.tasks=20
      # The maximum number of completed cruise control monitoring user tasks for which the response and access details will be cached.
      max.cached.completed.cruise.control.monitor.user.tasks=20
      # The maximum number of completed kafka admin user tasks for which the response and access details will be cached.
      max.cached.completed.kafka.admin.user.tasks=30
      # The maximum number of completed cruise control admin user tasks for which the response and access details will be cached.
      max.cached.completed.cruise.control.admin.user.tasks=30
      # The fallback maximum number of completed user tasks of certain type for which the response and access details will be cached.
      max.cached.completed.user.tasks=25
      # The maximum number of user tasks for concurrently running in async endpoints across all users.
      max.active.user.tasks=1000
      # Enable self healing for all anomaly detectors, unless the particular anomaly detector is explicitly disabled
      self.healing.enabled=true
      # Enable self healing for broker failure detector
      #self.healing.broker.failure.enabled=true
      # Enable self healing for goal violation detector
      #self.healing.goal.violation.enabled=true
      # Enable self healing for metric anomaly detector
      self.healing.metric.anomaly.enabled=false
      # Enable self healing for disk failure detector
      #self.healing.disk.failure.enabled=true
      # The multiplier applied to the threshold of distribution goals used by goal.violation.detector.
      #goal.violation.distribution.threshold.multiplier=2.50
      # configurations for the webserver
      # ================================
      # HTTP listen port
      webserver.http.port=9090
      # HTTP listen address
      webserver.http.address=0.0.0.0
      # Whether CORS support is enabled for API or not
      webserver.http.cors.enabled=false
      # Value for Access-Control-Allow-Origin
      webserver.http.cors.origin=http://localhost:8080/
      # Value for Access-Control-Request-Method
      webserver.http.cors.allowmethods=OPTIONS,GET,POST
      # Headers that should be exposed to the Browser (Webapp)
      # This is a special header that is used by the
      # User Tasks subsystem and should be explicitly
      # Enabled when CORS mode is used as part of the
      # Admin Interface
      webserver.http.cors.exposeheaders=User-Task-ID
      # REST API default prefix
      # (dont forget the ending *)
      webserver.api.urlprefix=/kafkacruisecontrol/*
      # Location where the Cruise Control frontend is deployed
      webserver.ui.diskpath=./cruise-control-ui/dist/
      # URL path prefix for UI
      # (dont forget the ending *)
      webserver.ui.urlprefix=/*
      # Time After which request is converted to Async
      webserver.request.maxBlockTimeMs=10000
      # Default Session Expiry Period
      webserver.session.maxExpiryTimeMs=60000
      # Session cookie path
      webserver.session.path=/
      # Server Access Logs
      webserver.accesslog.enabled=true
      # Location of HTTP Request Logs
      webserver.accesslog.path=access.log
      # HTTP Request Log retention days
      webserver.accesslog.retention.days=14
      # Configurations for servlet
      # ==========================
      # Enable two-step verification for processing POST requests.
      two.step.verification.enabled=false
      # The maximum time in milliseconds to retain the requests in two-step (verification) purgatory.
      two.step.purgatory.retention.time.ms=1209600000
      # The maximum number of requests in two-step (verification) purgatory.
      two.step.purgatory.max.requests=25
    # CapacityConfig describes Cruise Control config capacity.json
    capacityConfig: |
      {
        "brokerCapacities":[
          {
            "brokerId": "-1",
            "capacity": {
              "DISK": {"/kafka-logs1/kafka": "100000"},
              "CPU": {"num.cores": "5"},
              "NW_IN": "300000",
              "NW_OUT": "300000"
            },
            "doc": "This is the default capacity. Capacity unit used for disk is in MB, cpu is in cores, network throughput is in KB."
          }
        ]
      }
    # ClusterConfigs describes Cruise Control config clusterConfigs.json
    clusterConfig: |
      {
        "min.insync.replicas": 3
      }
